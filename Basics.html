<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>LaLonde tests</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Estimating the bias of Observational Methods using Randomized Controlled Trials with Imperfect Compliance</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Basics.html">Basics</a>
</li>
<li>
  <a href="Methods.html">Methods</a>
</li>
<li>
  <a href="Data.html">Data</a>
</li>
<li>
  <a href="Results.html">Results</a>
</li>
<li>
  <a href="About.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">LaLonde tests</h1>

</div>


<p>The most basic method used to estimate the bias of <a href="https://chabefer.github.io/STCI/OM.html">Observational Methods of causal inference</a> is the <a href="https://chabefer.github.io/STCI/LaLonde.html">LaLonde test</a>. <a href="https://chabefer.github.io/STCI/LaLonde.html">LaLonde tests</a> consist in comparing the causal effect estimated using an Observational Method to the causal effect estimated using a Randomized Controlled Trial. Formally, if we call <span class="math inline">\(\hat{\theta}_E\)</span> an experimental estimate of a causal parameter <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\hat{\theta}_{NE}\)</span> the non-experimental (or observational) estimate of <span class="math inline">\(\theta\)</span>, we can build an estimate of the bias of the observational method as follows:</p>
<p><span class="math display">\[\begin{align*}
  \hat{B}_{NE} &amp; = \hat{\theta}_{NE}-\hat{\theta}_E.
\end{align*}\]</span></p>
<p>If <span class="math inline">\(\hat{\theta}_E\)</span> is a consistent and unbiased estimator of <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(\hat{\theta}_{NE}\)</span> is a consistent and unbiased estimator of <span class="math inline">\(\theta_{NE}\)</span>, the population value of the observational estimator, then <span class="math inline">\(\hat{B}_{NE}\)</span> is a consistent and unbiased estimator of <span class="math inline">\(B_{NE}\)</span>, where <span class="math inline">\(B_{NE}=\theta_{NE}-\theta_E\)</span>.</p>
<p>The idea of LaLonde tests was first proposed by <a href="https://www.jstor.org/stable/1806062">LaLonde (1986)</a> in the context of the evaluation of Job Training Programs. LaLonde used the randomized experiment of the National Supported Work demonstration as an experimental benchmark and compared the experimental estimate to a set of observational estimates built using data on non-participants extracted from several administrative datasets. The technique was later re-used and perfected by <a href="https://www.jstor.org/stable/2999630">Heckman, Ichimura, Smith and Todd (1998)</a> using data from the evaluation of the Job Training Partnership Act, which contained both an experimental arm, but also collected data on the outcomes and characteristics of non participants. LaLonde tests have been extensively repeated since then, and we start having <a href="https://www.jstor.org/stable/3658561">meta-analysis</a> and <a href="https://www.tandfonline.com/doi/abs/10.1080/19345747.2016.1164781?journalCode=uree20">systematic reviews</a> and even <a href="https://pubmed.ncbi.nlm.nih.gov/32193818/">systematic reviews of systematic reviews</a> of LaLonde tests.</p>
<div id="issues-with-lalonde-tests" class="section level1">
<h1>Issues with LaLonde tests</h1>
<p>The applications in both <a href="https://www.jstor.org/stable/1806062">LaLonde (1986)</a> and <a href="https://www.jstor.org/stable/2999630">Heckman, Ichimura, Smith and Todd (1998)</a> suffered from several limitations though: they were small-scale, not standardised, and not hands-off. Both <a href="https://www.jstor.org/stable/1806062">LaLonde (1986)</a> and <a href="https://www.jstor.org/stable/2999630">Heckman, Ichimura, Smith and Todd (1998)</a> are small scale: they only use data from one RCT, creating two limitations. First, the external validity of the project is limited as we only learn about the bias in the context of two job-training programs in the US. Second, the work cannot recover the distribution of bias across contexts meaning that while LaLonde is critical of observational methods, it is possible that observational methods perform better elsewhere, or that they are on average unbiased.</p>
<p>LaLonde and most following work use an additional non-standardised, non-experimental comparison group to assess observational methods. This is because they use Randomized Controlled Trials with a <a href="https://chabefer.github.io/STCI/RCT.html#sec:design2">Self-Selection Design</a>, which does not require data collection on non-participants. This introduces two other potential biases: the new sample may not be perfectly comparable to the experimental sample, and the survey instruments or variable definitions may not match perfectly.</p>
<p>Observational methods require many choices to be made by the researcher and these degrees of freedom can generate conflicting results even within one dataset. There has been a 20-year debate over LaLonde’s results, in part because the LaLonde approach used so far is not hands-off. <a href="https://doi.org/10.2307/2669919">Dehejia and</a> <a href="https://doi.org/10.1162/003465302317331982">Wahba (1999, 2002)</a> re-analyse the LaLonde data with different methods and find that observational estimates are closer to experimental ones. However, <a href="https://doi.org/10.1016/j.jeconom.2004.04.011">Smith and Todd (2005)</a> find that Dehejia and Wahba’s results are sensitive to technical details such as the trimming method used.</p>
</div>
<div id="previous-intents-at-addressing-the-issues-with-lalonde-tests" class="section level1">
<h1>Previous intents at addressing the issues with LaLonde tests</h1>
<p>Previous studies have addressed some of these issues. Attempts at solving the small-scale problem typically perform meta-analysis of prior studies of observational bias, for example, <a href="https://doi.org/10.1177/0002716203254879">Glazerman et al. (2003)</a> for job training, <a href="https://doi.org/10.1080/19345747.2016.1164781">Wong et al. (2017)</a> for education, <a href="https://doi.org/10.1007/s11606-020-05713-5">Forbes and Dahabreh (2020)</a> in medicine and <a href="https://doi.org/10.1002/pam.22051">Chaplin et al. (2018)</a> for the <a href="https://chabefer.github.io/STCI/NE.html#regression-discontinuity-designs">regression discontinuity design (RDD)</a>. However, meta-analysis is constrained by the methodological choices of the original study authors. For example, some studies in <a href="https://doi.org/10.1002/pam.22051">Chaplin et al. (2018)</a> use parametric RDD and some non-parametric, complicating the comparison. In single context studies of bias, these choices might have been tailored and so overstate the performance of observational methods.</p>
<p>Others have noted the standardisation problem, and focused on imperfect compliance RCTs as a way to solve this issue, e.g., <a href="https://doi.org/10.1093/pan/mpj001">Arceneaux et al. (2006)</a> who assess matching methods in the context of a voter mobilisation experiment, and <a href="https://doi.org/10.1080/2330443X.2015.1084252">Gill et al. (2016)</a> who focus on the intention-to-treat estimate and assess observational methods in the context of charter-school lotteries, but still suffer from the small-scale problem. More recently, <a href="https://doi.org/10.1161/CIRCULATIONAHA.120.051718">Franklin et al (2020)</a> try to reproduce the results of RCTs in medicine by using large databases on patient-level from US commercial and Medicare payers. It is still unclear whether their outcome measurements are consistent between RCTs and observational methods.</p>
<p>Others have started using machine learning approaches to ensure that analyses are hands-off. <a href="https://www.nber.org/lecture/summer-institute-2018-meet-randomistas-useful-ml-tools-empirical-researchers">Duflo (2018)</a> looks at the performance of double machine learning estimators in the context of scholarships in Ghana, and calls for more LaLonde style research with this type of tool.</p>
<p>Finally, others have started using large scale datasets on repeated Randomized Controlled Trials with Imperfect compliance, but have failed to adopt a fully hands-on approach, or to use modern machine learning methods. <a href="https://doi.org/10.1287/mksc.2018.1135">Gordon et al. (2019)</a> evaluate two observational methods in 15 Facebook advertising experiments. <a href="https://doi.org/10.1257/aer.p20151016">Pritchett and Sandefur (2015)</a> compare experimental and non-experimental estimates of the effects of micro-credit on consumption and profits, using six studies. The estimates differ although the direction does not seem to be systematic. They also compare the magnitude of these biases to those incurred by extrapolating estimates across contexts, and find they tend to be smaller</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
